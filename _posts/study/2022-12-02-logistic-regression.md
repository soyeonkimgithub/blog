---
layout: post
title: Gradient Descent
categories: study
sitemap: false
hide_last_modified: true
published: true

---

## [Algorithm] Gradient Descent


project
### Summary
Task : prediction for the customers' future transaction (binary classification)
       This project is to recommend credit cards on ads banner by personalisation. For this, I made several clusters based on useRs' app usage. After that, I could define the characteristics of standardisation by each group.
Data : 200,000 lines with 200 variables
Tools : Python
ML Algorithms : LightGBM
Evaluation metrics : AUC

Why Standardisation?
What Did I Find?
Result?

### Key Points
1. 
2.

### Results

### Code
----

### Linear Regression
1. easy to use
2. easy to explain
3. predict continuous variable

### Logistic Regression
1. binary classification
2. easy to translate (based on linear regression)
3. used activation function in deep learning 

### Decision Tree
1. can be used in various problems
2. visualisation
3. based on latest algorithm 

### Random Forerst
1. fix overfitting and can be used in various problems
2. based on ensembles
3. good prediction

### Kmeans Clustering
1. unsupervised model
2. segmentation

#### XGBoost
1. one of tree model
2. 



clalssification 
- classify input data into categories
- predict cateogories (spam or ham, buy or sell or hold, cat or dog or mouse, positive text or negative or neutral)

regression 
- predict continuous numeric values
- given characteristics of a car predict mileage, given location and attributes of a home predict price, given GDP, health indicators predict life expectation

clustering 
- discover patterns and groupings in data
- document discovery: find all documents related to homicide cases, social media ad targeting: find all users who are interested in sports

dimensionality reduction 
- find latent or significant features in data
- find latent drivers of stock movements
- pre-process data to build more robust machine learning models
- improve performance of models

----
