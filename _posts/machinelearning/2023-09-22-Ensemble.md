---
layout: post
title: Ensemble
categories: machinelearning
sitemap: false
hide_last_modified: true
published: true
---

## [ML] Ensemble

### background

Ensemble learning has many types, below two are popular.

### description

- bagging
    - each model is trained on sample of same training dataset, parallel
    - predictions are made by aggregation of all the (weak) models
    - average for regression, take the most dominant vote for classification
    - avoids overfitting as you are averaging/voting output from multiple models
    - reduces variance error
    - i.e. Random Forest
- boosting
    - focus on modelâ€™s previous mistakes and upgrade itself
    - training is sequential
    - increases accuracy, decreases bias error
    - i.e. AdaBoost, XGBoost